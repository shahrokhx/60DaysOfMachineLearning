{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Form\n",
    "\n",
    "## (A) All Numerical Values\n",
    "\n",
    "### (1) Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.0\n",
      "0.25.3\n",
      "1.4.1\n",
      "0.22.2.post1\n"
     ]
    }
   ],
   "source": [
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "import scipy   as sp\n",
    "import sklearn as sk\n",
    "\n",
    "# from sklearn.impute          import SimpleImputer\n",
    "# from sklearn.preprocessing   import StandardScaler\n",
    "# from sklearn.preprocessing   import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "print (np.__version__)\n",
    "print (pd.__version__)\n",
    "print (sp.__version__)\n",
    "print (sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Importing Data\n",
    "The dataset includes missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Index   \"sq ft\"   \"Beds\"   \"Baths\"   \"Zip\"   \"Year\"   \"List Price ($)\"\n",
      "0       1    2222.0      3.0       3.5   32312     1981             250000\n",
      "1       2    1628.0      3.0       2.0   32308     2009             185000\n",
      "2       3    3824.0      5.0       4.0   32312     1954             399000\n",
      "3       4    1137.0      3.0       2.0   32309     1993             150000\n",
      "4       5    3560.0      6.0       4.0   32309     1973             315000\n",
      "5       6    2893.0      4.0       NaN   32312     1994             699000\n",
      "6       7    3631.0      4.0       3.0   32309     1996             649000\n",
      "7       8    2483.0      4.0       3.0   32312     2016             399000\n",
      "8       9       NaN      4.0       4.0   32312     2002             613000\n",
      "9      10    1997.0      3.0       3.0   32311     2006             295000\n",
      "10     11    2097.0      4.0       3.0   32311     2016             290000\n",
      "11     12    3200.0      5.0       4.0   32312     1964             465000\n",
      "12     13    4892.0      5.0       6.0   32311     2005             799900\n",
      "13     14    1128.0      2.0       1.0   32303     1955              89000\n",
      "14     15       NaN      3.0       2.0   32301     2006             143000\n",
      "15     16    4242.0      4.0       5.0   32303     2007             569000\n",
      "16     17    2533.0      3.0       2.0   32310     1991             365000\n",
      "17     18    1158.0      NaN       2.0   32303     1993             155000\n",
      "18     19    2497.0      4.0       4.0   32309     1990             289000\n",
      "19     20    4010.0      5.0       3.0   32309     2002             549900\n",
      "[[1.0000e+00 2.2220e+03 3.0000e+00 3.5000e+00 3.2312e+04 1.9810e+03]\n",
      " [2.0000e+00 1.6280e+03 3.0000e+00 2.0000e+00 3.2308e+04 2.0090e+03]\n",
      " [3.0000e+00 3.8240e+03 5.0000e+00 4.0000e+00 3.2312e+04 1.9540e+03]\n",
      " [4.0000e+00 1.1370e+03 3.0000e+00 2.0000e+00 3.2309e+04 1.9930e+03]\n",
      " [5.0000e+00 3.5600e+03 6.0000e+00 4.0000e+00 3.2309e+04 1.9730e+03]\n",
      " [6.0000e+00 2.8930e+03 4.0000e+00        nan 3.2312e+04 1.9940e+03]\n",
      " [7.0000e+00 3.6310e+03 4.0000e+00 3.0000e+00 3.2309e+04 1.9960e+03]\n",
      " [8.0000e+00 2.4830e+03 4.0000e+00 3.0000e+00 3.2312e+04 2.0160e+03]\n",
      " [9.0000e+00        nan 4.0000e+00 4.0000e+00 3.2312e+04 2.0020e+03]\n",
      " [1.0000e+01 1.9970e+03 3.0000e+00 3.0000e+00 3.2311e+04 2.0060e+03]\n",
      " [1.1000e+01 2.0970e+03 4.0000e+00 3.0000e+00 3.2311e+04 2.0160e+03]\n",
      " [1.2000e+01 3.2000e+03 5.0000e+00 4.0000e+00 3.2312e+04 1.9640e+03]\n",
      " [1.3000e+01 4.8920e+03 5.0000e+00 6.0000e+00 3.2311e+04 2.0050e+03]\n",
      " [1.4000e+01 1.1280e+03 2.0000e+00 1.0000e+00 3.2303e+04 1.9550e+03]\n",
      " [1.5000e+01        nan 3.0000e+00 2.0000e+00 3.2301e+04 2.0060e+03]\n",
      " [1.6000e+01 4.2420e+03 4.0000e+00 5.0000e+00 3.2303e+04 2.0070e+03]\n",
      " [1.7000e+01 2.5330e+03 3.0000e+00 2.0000e+00 3.2310e+04 1.9910e+03]\n",
      " [1.8000e+01 1.1580e+03        nan 2.0000e+00 3.2303e+04 1.9930e+03]\n",
      " [1.9000e+01 2.4970e+03 4.0000e+00 4.0000e+00 3.2309e+04 1.9900e+03]\n",
      " [2.0000e+01 4.0100e+03 5.0000e+00 3.0000e+00 3.2309e+04 2.0020e+03]]\n",
      "[250000 185000 399000 150000 315000 699000 649000 399000 613000 295000\n",
      " 290000 465000 799900  89000 143000 569000 365000 155000 289000 549900]\n"
     ]
    }
   ],
   "source": [
    "dataSet = pd.read_csv('../Data/zillow_incomplete.csv')\n",
    "print (dataSet)\n",
    "\n",
    "X = dataSet.iloc[:, :-1].values\n",
    "Y = dataSet.iloc[:,  -1].values\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Handling Missing Data\n",
    "\n",
    "Imputer Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
      "              missing_values=nan, strategy='mean', verbose=0)\n",
      "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
      "              missing_values=nan, strategy='mean', verbose=0)\n",
      "[[1.00000000e+00 2.22200000e+03 3.00000000e+00 3.50000000e+00\n",
      "  3.23120000e+04 1.98100000e+03]\n",
      " [2.00000000e+00 1.62800000e+03 3.00000000e+00 2.00000000e+00\n",
      "  3.23080000e+04 2.00900000e+03]\n",
      " [3.00000000e+00 3.82400000e+03 5.00000000e+00 4.00000000e+00\n",
      "  3.23120000e+04 1.95400000e+03]\n",
      " [4.00000000e+00 1.13700000e+03 3.00000000e+00 2.00000000e+00\n",
      "  3.23090000e+04 1.99300000e+03]\n",
      " [5.00000000e+00 3.56000000e+03 6.00000000e+00 4.00000000e+00\n",
      "  3.23090000e+04 1.97300000e+03]\n",
      " [6.00000000e+00 2.89300000e+03 4.00000000e+00 3.18421053e+00\n",
      "  3.23120000e+04 1.99400000e+03]\n",
      " [7.00000000e+00 3.63100000e+03 4.00000000e+00 3.00000000e+00\n",
      "  3.23090000e+04 1.99600000e+03]\n",
      " [8.00000000e+00 2.48300000e+03 4.00000000e+00 3.00000000e+00\n",
      "  3.23120000e+04 2.01600000e+03]\n",
      " [9.00000000e+00 2.72955556e+03 4.00000000e+00 4.00000000e+00\n",
      "  3.23120000e+04 2.00200000e+03]\n",
      " [1.00000000e+01 1.99700000e+03 3.00000000e+00 3.00000000e+00\n",
      "  3.23110000e+04 2.00600000e+03]\n",
      " [1.10000000e+01 2.09700000e+03 4.00000000e+00 3.00000000e+00\n",
      "  3.23110000e+04 2.01600000e+03]\n",
      " [1.20000000e+01 3.20000000e+03 5.00000000e+00 4.00000000e+00\n",
      "  3.23120000e+04 1.96400000e+03]\n",
      " [1.30000000e+01 4.89200000e+03 5.00000000e+00 6.00000000e+00\n",
      "  3.23110000e+04 2.00500000e+03]\n",
      " [1.40000000e+01 1.12800000e+03 2.00000000e+00 1.00000000e+00\n",
      "  3.23030000e+04 1.95500000e+03]\n",
      " [1.50000000e+01 2.72955556e+03 3.00000000e+00 2.00000000e+00\n",
      "  3.23010000e+04 2.00600000e+03]\n",
      " [1.60000000e+01 4.24200000e+03 4.00000000e+00 5.00000000e+00\n",
      "  3.23030000e+04 2.00700000e+03]\n",
      " [1.70000000e+01 2.53300000e+03 3.00000000e+00 2.00000000e+00\n",
      "  3.23100000e+04 1.99100000e+03]\n",
      " [1.80000000e+01 1.15800000e+03 3.89473684e+00 2.00000000e+00\n",
      "  3.23030000e+04 1.99300000e+03]\n",
      " [1.90000000e+01 2.49700000e+03 4.00000000e+00 4.00000000e+00\n",
      "  3.23090000e+04 1.99000000e+03]\n",
      " [2.00000000e+01 4.01000000e+03 5.00000000e+00 3.00000000e+00\n",
      "  3.23090000e+04 2.00200000e+03]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#imputer= SimpleImputer(missing_values = \"NaN\" , strategy = \"mean\") \n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "print(imputer)\n",
    "\n",
    "imputer=imputer.fit(X)\n",
    "print(imputer)\n",
    "\n",
    "X=imputer.transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      "[[-1.64750894e+00 -4.87453380e-01 -9.48699712e-01  2.73797115e-01\n",
      "   8.95266022e-01 -6.45008802e-01]\n",
      " [-1.47408695e+00 -1.05792750e+00 -9.48699712e-01 -1.02673918e+00\n",
      "  -2.59915942e-01  9.05226946e-01]\n",
      " [-1.30066495e+00  1.05109803e+00  1.17192317e+00  7.07309214e-01\n",
      "   8.95266022e-01 -2.13987899e+00]\n",
      " [-1.12724296e+00 -1.52948102e+00 -9.48699712e-01 -1.02673918e+00\n",
      "   2.88795491e-02  1.93779468e-02]\n",
      " [-9.53820966e-01  7.97553975e-01  2.23223462e+00  7.07309214e-01\n",
      "   2.88795491e-02 -1.08793330e+00]\n",
      " [-7.80398973e-01  1.56971086e-01  1.11611731e-01  0.00000000e+00\n",
      "   8.95266022e-01  7.47435093e-02]\n",
      " [-6.06976979e-01  8.65741959e-01  1.11611731e-01 -1.59714984e-01\n",
      "   2.88795491e-02  1.85474634e-01]\n",
      " [-4.33554985e-01 -2.36790510e-01  1.11611731e-01 -1.59714984e-01\n",
      "   8.95266022e-01  1.29278588e+00]\n",
      " [-2.60132991e-01  0.00000000e+00  1.11611731e-01  7.07309214e-01\n",
      "   8.95266022e-01  5.17668009e-01]\n",
      " [-8.67109970e-02 -7.03542061e-01 -9.48699712e-01 -1.59714984e-01\n",
      "   6.06470531e-01  7.39130258e-01]\n",
      " [ 8.67109970e-02 -6.07502647e-01  1.11611731e-01 -1.59714984e-01\n",
      "   6.06470531e-01  1.29278588e+00]\n",
      " [ 2.60132991e-01  4.51812086e-01  1.17192317e+00  7.07309214e-01\n",
      "   8.95266022e-01 -1.58622336e+00]\n",
      " [ 4.33554985e-01  2.07679897e+00  1.17192317e+00  2.44135761e+00\n",
      "   6.06470531e-01  6.83764696e-01]\n",
      " [ 6.06976979e-01 -1.53812457e+00 -2.00901115e+00 -1.89376338e+00\n",
      "  -1.70389340e+00 -2.08451343e+00]\n",
      " [ 7.80398973e-01  0.00000000e+00 -9.48699712e-01 -1.02673918e+00\n",
      "  -2.28148438e+00  7.39130258e-01]\n",
      " [ 9.53820966e-01  1.45254278e+00  1.11611731e-01  1.57433341e+00\n",
      "  -1.70389340e+00  7.94495821e-01]\n",
      " [ 1.12724296e+00 -1.88770803e-01 -9.48699712e-01 -1.02673918e+00\n",
      "   3.17675040e-01 -9.13531780e-02]\n",
      " [ 1.30066495e+00 -1.50931274e+00  4.70872871e-16 -1.02673918e+00\n",
      "  -1.70389340e+00  1.93779468e-02]\n",
      " [ 1.47408695e+00 -2.23344992e-01  1.11611731e-01  7.07309214e-01\n",
      "   2.88795491e-02 -1.46718740e-01]\n",
      " [ 1.64750894e+00  1.22973134e+00  1.17192317e+00 -1.59714984e-01\n",
      "   2.88795491e-02  5.17668009e-01]]\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "\n",
    "X = scalar.fit_transform(X)\n",
    "print (\"X = \")\n",
    "print (X)\n",
    "print (\"=============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Splitting data into trainig and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = \n",
      "[[ 8.67109970e-02 -6.07502647e-01  1.11611731e-01 -1.59714984e-01\n",
      "   6.06470531e-01  1.29278588e+00]\n",
      " [ 1.30066495e+00 -1.50931274e+00  4.70872871e-16 -1.02673918e+00\n",
      "  -1.70389340e+00  1.93779468e-02]\n",
      " [-6.06976979e-01  8.65741959e-01  1.11611731e-01 -1.59714984e-01\n",
      "   2.88795491e-02  1.85474634e-01]\n",
      " [ 6.06976979e-01 -1.53812457e+00 -2.00901115e+00 -1.89376338e+00\n",
      "  -1.70389340e+00 -2.08451343e+00]\n",
      " [-9.53820966e-01  7.97553975e-01  2.23223462e+00  7.07309214e-01\n",
      "   2.88795491e-02 -1.08793330e+00]\n",
      " [-1.30066495e+00  1.05109803e+00  1.17192317e+00  7.07309214e-01\n",
      "   8.95266022e-01 -2.13987899e+00]\n",
      " [-7.80398973e-01  1.56971086e-01  1.11611731e-01  0.00000000e+00\n",
      "   8.95266022e-01  7.47435093e-02]\n",
      " [ 7.80398973e-01  0.00000000e+00 -9.48699712e-01 -1.02673918e+00\n",
      "  -2.28148438e+00  7.39130258e-01]\n",
      " [-8.67109970e-02 -7.03542061e-01 -9.48699712e-01 -1.59714984e-01\n",
      "   6.06470531e-01  7.39130258e-01]\n",
      " [-4.33554985e-01 -2.36790510e-01  1.11611731e-01 -1.59714984e-01\n",
      "   8.95266022e-01  1.29278588e+00]\n",
      " [ 1.12724296e+00 -1.88770803e-01 -9.48699712e-01 -1.02673918e+00\n",
      "   3.17675040e-01 -9.13531780e-02]\n",
      " [ 2.60132991e-01  4.51812086e-01  1.17192317e+00  7.07309214e-01\n",
      "   8.95266022e-01 -1.58622336e+00]\n",
      " [-1.12724296e+00 -1.52948102e+00 -9.48699712e-01 -1.02673918e+00\n",
      "   2.88795491e-02  1.93779468e-02]\n",
      " [-1.64750894e+00 -4.87453380e-01 -9.48699712e-01  2.73797115e-01\n",
      "   8.95266022e-01 -6.45008802e-01]\n",
      " [ 9.53820966e-01  1.45254278e+00  1.11611731e-01  1.57433341e+00\n",
      "  -1.70389340e+00  7.94495821e-01]\n",
      " [ 4.33554985e-01  2.07679897e+00  1.17192317e+00  2.44135761e+00\n",
      "   6.06470531e-01  6.83764696e-01]]\n",
      "Y_train = \n",
      "[290000 155000 649000  89000 315000 399000 699000 143000 295000 399000\n",
      " 365000 465000 150000 250000 569000 799900]\n",
      "---------------------------------------------\n",
      "X_test = \n",
      "[[ 1.47408695 -0.22334499  0.11161173  0.70730921  0.02887955 -0.14671874]\n",
      " [-1.47408695 -1.0579275  -0.94869971 -1.02673918 -0.25991594  0.90522695]\n",
      " [ 1.64750894  1.22973134  1.17192317 -0.15971498  0.02887955  0.51766801]\n",
      " [-0.26013299  0.          0.11161173  0.70730921  0.89526602  0.51766801]]\n",
      "Y_test = \n",
      "[289000 185000 549900 613000]\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 0)\n",
    "\n",
    "print (\"X_train = \")\n",
    "print (X_train)\n",
    "print (\"Y_train = \")\n",
    "print (Y_train)\n",
    "print (\"---------------------------------------------\")\n",
    "print (\"X_test = \")\n",
    "print (X_test)\n",
    "print (\"Y_test = \")\n",
    "print (Y_test)\n",
    "print (\"=============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "## (B) Includes Categorical Data\n",
    "\n",
    "### (1) Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19.0\n",
      "0.25.3\n",
      "1.4.1\n",
      "0.22.2.post1\n"
     ]
    }
   ],
   "source": [
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "import scipy   as sp\n",
    "import sklearn as sk\n",
    "\n",
    "# from sklearn.impute          import SimpleImputer\n",
    "# from sklearn.preprocessing   import StandardScaler\n",
    "# from sklearn.preprocessing   import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "print (np.__version__)\n",
    "print (pd.__version__)\n",
    "print (sp.__version__)\n",
    "print (sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Importing Data\n",
    "The dataset includes missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "dataSet = pd.read_csv('../Data/dataset1.csv')\n",
    "print (dataSet)\n",
    "\n",
    "X = dataSet.iloc[:, :-1].values\n",
    "Y = dataSet.iloc[:,  -1].values\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44.0 72000.0]\n",
      " [27.0 48000.0]\n",
      " [30.0 54000.0]\n",
      " [38.0 61000.0]\n",
      " [40.0 nan]\n",
      " [35.0 58000.0]\n",
      " [nan 52000.0]\n",
      " [48.0 79000.0]\n",
      " [50.0 83000.0]\n",
      " [37.0 67000.0]]\n",
      "[72000.0 48000.0 54000.0 61000.0 nan 58000.0 52000.0 79000.0 83000.0\n",
      " 67000.0]\n",
      "[[44.0 72000.0]\n",
      " [27.0 48000.0]\n",
      " [30.0 54000.0]\n",
      " [38.0 61000.0]\n",
      " [40.0 nan]\n",
      " [35.0 58000.0]\n",
      " [nan 52000.0]\n",
      " [48.0 79000.0]\n",
      " [50.0 83000.0]\n",
      " [37.0 67000.0]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False  True]\n",
      " [False False]\n",
      " [ True False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]]\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print (X[:, 1:3])\n",
    "print (X[:, -1])\n",
    "print (X[:, -2:])\n",
    "# imputer = imputer.fit(X[:, 1:3])\n",
    "\n",
    "\n",
    "print(   type(X)                           )\n",
    "print(   pd.isnull(X[:, 1:3])              )\n",
    "print(   np.any(pd.isnull(X[:, 1:3]))      )\n",
    "print(   np.all(pd.isnull(X[:, 1:3]))      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
      "              missing_values=nan, strategy='mean', verbose=0)\n",
      "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
      "              missing_values=nan, strategy='mean', verbose=0)\n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "# Handling missing data\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#imputer= SimpleImputer(missing_values = \"NaN\" , strategy = \"mean\") \n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "print(imputer)\n",
    "\n",
    "imputer=imputer.fit(X[:,1:3])\n",
    "print(imputer)\n",
    "\n",
    "X[:,1:3]=imputer.transform(X[:,1:3])\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 44.0 72000.0]\n",
      " [2 27.0 48000.0]\n",
      " [1 30.0 54000.0]\n",
      " [2 38.0 61000.0]\n",
      " [1 40.0 63777.77777777778]\n",
      " [0 35.0 58000.0]\n",
      " [2 38.77777777777778 52000.0]\n",
      " [0 48.0 79000.0]\n",
      " [1 50.0 83000.0]\n",
      " [0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "X[ : , 0] = encoder.fit_transform(X[ : , 0])\n",
    "print (X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Splitting data into trainig and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 40.0 63777.77777777778]\n",
      " [0 37.0 67000.0]\n",
      " [2 27.0 48000.0]\n",
      " [2 38.77777777777778 52000.0]\n",
      " [0 48.0 79000.0]\n",
      " [2 38.0 61000.0]\n",
      " [0 44.0 72000.0]\n",
      " [0 35.0 58000.0]]\n",
      "['Yes' 'Yes' 'Yes' 'No' 'Yes' 'No' 'No' 'Yes']\n",
      "[[1 30.0 54000.0]\n",
      " [1 50.0 83000.0]]\n",
      "['No' 'No']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 0)\n",
    "\n",
    "print (X_train)\n",
    "print (Y_train)\n",
    "\n",
    "print (X_test)\n",
    "print (Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13483997  0.26306757  0.12381479]\n",
      " [-0.94387981 -0.25350148  0.46175632]\n",
      " [ 1.21355975 -1.97539832 -1.53093341]\n",
      " [ 1.21355975  0.05261351 -1.11141978]\n",
      " [-0.94387981  1.64058505  1.7202972 ]\n",
      " [ 1.21355975 -0.0813118  -0.16751412]\n",
      " [-0.94387981  0.95182631  0.98614835]\n",
      " [-0.94387981 -0.59788085 -0.48214934]]\n",
      "[[ 0. -1. -1.]\n",
      " [ 0.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test  = scalar.fit_transform(X_test)\n",
    "\n",
    "print (X_train)\n",
    "print (X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
